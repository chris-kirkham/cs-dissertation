# Dynamic Emotion Recognition of MIDI Music using Recurrent Neural Networks
Undergraduate dissertation project for Computer Science with Artificial Intelligence BSc (hons) (2018), University of Nottingham. This project provides a system for dynamic/continuous emotion recognition of MIDI music files. 

## src
This folder contains the emotion prediction program, 'emotion_recognition_predict.py', as well as the 'chord_predictions' and 'emotion_predictions' subfolders for storing predicted chord and emotion data. 

### emotion_recognition_predict.py
This program allows a user to predict the emotional expression of an input MIDI file. It outputs a visual representation of the emotions predicted, and, optionally, .csv files of the chord and emotion labels generated by the program.

#### Dependencies
Dependencies are referenced in the dissertation body: Keras, NumPy, Pretty-midi, Matplotlib

#### How to use

Navigate to the /src folder, open a command line window, and type `emotion_recognition_predict.py filename.mid` to run the program for `filename.mid`

Optional commands:

`--output`: outputs chord and emotion .csv files in /src/chord_predictions and /src/emotion_predictions respectively.  

## utilities
This folder contains utility scripts which were used to help process, label and augment training data in the course of the project. They may prove useful 

### process_music_and_chord_labels.py
A script to preprocess a MIDI file and its corresponding hand-labelled chord label file - for input to the chord neural net - simultaneously (the chord labels require information from the MIDI file to be processed, so we may as well process them both at the same time).
This program takes the following command-line arguments, in this order: 

1. _input MIDI file_ - the input .mid music file 
2. _input label file_ - the input .csv label file
3. _root note of music_ - the root note of the input piece of music as a string, only used for file naming
4. _number of bars to split output at_ - because most pieces of music are much longer than intended for this system's neural nets, we must split larger pieces into smaller chunks; this is the number of bars in length each output section of music will be (any music remaining after the last full _n_ bars of the piece will be processed as-is). A good basic rule is 16 bars for very fast pieces and/or pieces with very small measures, 8 bars for medium-fast pieces, 4 bars for slow pieces - this will likely produce sequences of 200-300 timesteps

For example, `Python process_music_and_chord_labels.py music.mid chords.csv C 8` would process `music.mid` - which has a root note of C - and its corresponding label file, `chords.csv`, splitting the output into sequences of 8 bars in length. 

##### writing your own chord labels
Each chord label must be a row in the format `bar, chord` where `bar` is the musical bar/measure when the chord begins; decimals are allowed. If a piece of music has a pickup bar (i.e. an incomplete bar of music before the first complete bar), the chord labels should start at bar `0`, otherwise start at bar `1`.

For example, the chord label `1.5, F#Maj` would indicate the chord F# major starting halfway through the first full bar of music.

A set of chord labels for one piece of music may look like:

```
0, CMaj
1, CMaj
3, FMaj
3.5, GMaj
4, CMaj
```

A full list of valid chords for labelling can be found at the bottom of this document.

### process_music_and_emotion_labels.py 
A script to preprocess a MIDI file and its corresponding emotion label file for input to the emotion recognition neural net; processed simultaneously for the same reason as for chord label processing.
This program takes the following arguments, in this order:

1. _input MIDI file_ - the input .mid music fiel
2. _input label file_ - the input .csv label file
3. _music root note_ - the root note of the input piece of music as a string
4. _label type_ - 0 = normal labels, 1 = simplified labels 
4. _number of bars to split output at_ - same as process_music_and_chord_labels.py

For example, `Python process_music_and_emotion_labels.py music.mid emotions.csv C 8` would process `music.mid` - which has a root note of C - and its corresponding label file, `chords.csv`, splitting the output into sequences of 8 bars in length. 

##### writing your own emotion labels
Each emotion label must be a row in the format `bar, emotion, modifier` where `modifier` is either `-` or `~`. Emotions are labelled as discrete emotion words ("happy", "sad", "relaxed" etc.); these are converted to a dimensional representation (valence, arousal) when preprocessed.

`-` will  use the dimensional representation of the corresponding emotion label for its duration.
`~` will create a linear transition between the dimensional representation of its corresponding emotion label and that of the next emotion label in the file (__N.B.__ `~` cannot be used for the last label in a file) from the start of the first label to the start of the next label.

For example, if we assume there are 3 timesteps in a bar:
```
0, Relaxed, - #(1, 0.25)
1, Happy, - #(1, 1)
```
would process to
```
(1,0.25),(1,0.25),(1,0.25),(1,1),(1,1),...
```
whereas 
```
0, Relaxed, ~
1, Happy, -
```
would process to
```
(1,0.25),(1,0.5),(1,0.75),(1,1),(1,1),...
```

In this way, we can easily label smooth (linear) transitions between emotional states in music. A full list of valid emotion labels can be found at the bottom of this document.

### transpose_music_and_labels_batch 
A script to augment preprocessed training data by transposing a music sequence or batch of music sequences to all 12 tones of the chromatic scale. Renames output files with transposed root notes.
Batches of music files to be transposed must be placed in a separate directory containing ONLY those files to be transposed; corresponding label files must be placed in a different directory, also containing ONLY those label files to be transposed. These directories are passed as command-line arguments to the program.
This program takes the following arguments, in this order:

1. _(processed) music sequences directory_
2. _(processed) labels directory_
3. _root note of music_ - only used for file naming. __N.B.__ this script was intended to be used in batches of a piece or piece(s) with the same root note. If using it for pieces with different roots, you can put any root note here - the roots in the output filenames will be wrong, but the music/label files will still correspond to each other when sorting by name.
4. _label type_ - 0 = chord labels, 1 = emotion labels. The data for emotion labels will not be changed during transposition, but new output files will be created to correspond to the transposed music. 

## example_midi
The `example_midi` folder contains example MIDI files which can be used with `emotion_recognition_predict.py`. To use the files as input from the `example_midi` folder, open a command window in the `src` folder and use `emotion_recognition_predict.py ../example_midi/filename.mid`

## Appendix
### Valid chord labels
Valid chord labels for labelling training data are as follows (label processing script is not case-sensitive):
```
"None-","F#7th","A#Dim","F#Maj","F#Min","C#7th","FDim","C#Maj","C#Min","G#7th","G#Maj","CDim","G#Min","D#7th","GDim","D#Maj","D#Min","A#7th","DDim","A#Maj","A#Min","F7th","ADim","FMaj","FMin","C7th","EDim","CMaj","CMin","G7th","BDim","GMaj","GMin","D7th","F#Dim","DMaj","DMin","A7th","C#Dim","AMaj","AMin","E7th","G#Dim","EMaj","EMin","B7th","D#Dim","BMaj","BMin","C-/D#-/F#-/A-Dim7","C#-/E-/G-/A#-Dim7","D-/F-/G#-/B-Dim7"
```
### Valid emotion labels
For ease of labelling training data, emotion labels are abbreviated. Valid labels are as follows:
```
Ca (calm), Ha (happy), Pl (pleased), Re (relaxed), Pe (peaceful), Sl (sleepy), Sa (sad), Bo (bored), Ne (nervous), An (angry), Ex (excited) 
```
